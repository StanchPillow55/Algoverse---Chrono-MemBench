{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChronoSAE Quickstart Demo\n",
    "\n",
    "This notebook demonstrates the ChronoSAE system end-to-end, including:\n",
    "- Environment setup and device detection\n",
    "- Loading a trained checkpoint\n",
    "- Running inference and training steps\n",
    "- Visualizing the six dials (Mem-Absorption, TPG, Cap-Gauge, ICL-Persistence, Weight-Œî, RAG-Trace)\n",
    "- Examining saved metrics\n",
    "\n",
    "**Compatible with**: CPU, GTX 1070, and other CUDA devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Better stack trace display\n",
    "%xmode Verbose\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "def print_exception():\n",
    "    \"\"\"Print full traceback inline for debugging\"\"\"\n",
    "    exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "    if exc_type is not None:\n",
    "        print(\"\\n=== FULL TRACEBACK ===\")\n",
    "        traceback.print_exception(exc_type, exc_value, exc_traceback)\n",
    "        print(\"======================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Set up paths\n",
    "project_root = Path(os.getcwd()).parent if 'notebooks' in os.getcwd() else Path(os.getcwd())\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path includes: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device detection and capability check\n",
    "def detect_device():\n",
    "    \"\"\"Detect best available device and check capabilities\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB\n",
    "        \n",
    "        print(f\"üöÄ CUDA Device: {gpu_name}\")\n",
    "        print(f\"üíæ GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        # Check if it's GTX 1070 or similar\n",
    "        if 'GTX 1070' in gpu_name or gpu_memory < 12:\n",
    "            print(\"‚ö†Ô∏è  Mid-range GPU detected - using conservative settings\")\n",
    "            use_mixed_precision = False  # GTX 1070 doesn't have Tensor Cores\n",
    "        else:\n",
    "            print(\"‚úÖ High-end GPU detected - enabling mixed precision\")\n",
    "            use_mixed_precision = True\n",
    "            \n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        use_mixed_precision = False\n",
    "        print(\"üçé Apple Silicon MPS detected\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        use_mixed_precision = False\n",
    "        print(\"üíª Using CPU\")\n",
    "    \n",
    "    print(f\"üîß Device: {device}\")\n",
    "    print(f\"‚ö° Mixed Precision: {use_mixed_precision}\")\n",
    "    \n",
    "    return device, use_mixed_precision\n",
    "\n",
    "device, use_amp = detect_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ChronoSAE components\n",
    "try:\n",
    "    from src.algoverse.chrono.chrono_sae.model import ChronoSAE, ChronoSAEConfig, create_chrono_sae\n",
    "    from membench_x.metrics import (\n",
    "        MemAbsorptionHook, TPGHook, CapGaugeHook, \n",
    "        ICLPersistenceHook, WeightDeltaHook, RAGTraceHook\n",
    "    )\n",
    "    from training.loop import create_training_loop\n",
    "    print(\"‚úÖ Successfully imported ChronoSAE components\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Creating fallback implementation...\")\n",
    "    \n",
    "    # Fallback dummy implementation for demo purposes\n",
    "    class ChronoSAEConfig:\n",
    "        def __init__(self, **kwargs):\n",
    "            for k, v in kwargs.items():\n",
    "                setattr(self, k, v)\n",
    "    \n",
    "    class ChronoSAE(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "            self.encoder = nn.Linear(config.d_model, config.d_sae)\n",
    "            self.decoder = nn.Linear(config.d_sae, config.d_model)\n",
    "            self.temporal_dropout = nn.Dropout(config.temporal_dropout_p)\n",
    "            \n",
    "        def forward(self, x, compute_loss=True):\n",
    "            z = torch.relu(self.encoder(x))\n",
    "            z = self.temporal_dropout(z) \n",
    "            x_recon = self.decoder(z)\n",
    "            \n",
    "            if compute_loss:\n",
    "                mse_loss = nn.functional.mse_loss(x_recon, x)\n",
    "                l1_loss = z.abs().mean()\n",
    "                temporal_loss = torch.tensor(0.01, device=x.device)\n",
    "                \n",
    "                total_loss = mse_loss + self.config.lambda_sparsity * l1_loss + self.config.beta_tpg * temporal_loss\n",
    "                \n",
    "                return {\n",
    "                    'output': x_recon,\n",
    "                    'activations': z,\n",
    "                    'loss': total_loss,\n",
    "                    'loss_components': {\n",
    "                        'mse_loss': mse_loss,\n",
    "                        'l1_loss': l1_loss, \n",
    "                        'temporal_loss': temporal_loss\n",
    "                    }\n",
    "                }\n",
    "            return {'output': x_recon, 'activations': z}\n",
    "        \n",
    "        def get_sparsity_metrics(self, activations):\n",
    "            \"\"\"Compute sparsity metrics for activations\"\"\"\n",
    "            with torch.no_grad():\n",
    "                # L0 sparsity (fraction of non-zero elements)\n",
    "                l0_sparsity = (activations.abs() > 1e-6).float().mean().item()\n",
    "                \n",
    "                # L1 norm\n",
    "                l1_norm = activations.abs().mean().item()\n",
    "                \n",
    "                # Max activation\n",
    "                max_activation = activations.abs().max().item()\n",
    "                \n",
    "                return {\n",
    "                    'l0_sparsity': l0_sparsity,\n",
    "                    'l1_norm': l1_norm,\n",
    "                    'max_activation': max_activation\n",
    "                }\n",
    "    \n",
    "    def create_chrono_sae(config):\n",
    "        return ChronoSAE(config)\n",
    "    \n",
    "    print(\"‚úÖ Fallback implementation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create and Configure ChronoSAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration optimized for demo\n",
    "config = ChronoSAEConfig(\n",
    "    d_model=256,           # Smaller model for demo\n",
    "    d_sae=1024,           # 4x expansion\n",
    "    temporal_dropout_p=0.1,\n",
    "    lambda_sparsity=1e-4,\n",
    "    beta_tpg=1e-3,\n",
    "    device=str(device)\n",
    ")\n",
    "\n",
    "# Create model\n",
    "model = create_chrono_sae(config)\n",
    "model = model.to(device)\n",
    "\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "model_size_mb = param_count * 4 / (1024**2)  # Assuming float32\n",
    "\n",
    "print(f\"üß† ChronoSAE Model Created:\")\n",
    "print(f\"   Parameters: {param_count:,}\")\n",
    "print(f\"   Model Size: {model_size_mb:.1f} MB\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Print model architecture\n",
    "print(f\"\\nüìê Model Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Dummy Data and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate structured dummy data (simulating transformer activations)\n",
    "def create_demo_data(batch_size=8, seq_len=32, d_model=256, device='cpu'):\n",
    "    \"\"\"Create structured dummy data with temporal patterns\"\"\"\n",
    "    \n",
    "    # Base random data\n",
    "    data = torch.randn(batch_size, seq_len, d_model, device=device)\n",
    "    \n",
    "    # Add temporal structure\n",
    "    for b in range(batch_size):\n",
    "        for t in range(1, seq_len):\n",
    "            # Add some temporal correlation\n",
    "            data[b, t] = 0.7 * data[b, t] + 0.3 * data[b, t-1]\n",
    "    \n",
    "    # Add some attention-like patterns\n",
    "    attention_weights = torch.softmax(torch.randn(batch_size, seq_len, seq_len), dim=-1)\n",
    "    for b in range(batch_size):\n",
    "        data[b] = torch.matmul(attention_weights[b], data[b])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Create demo data\n",
    "demo_data = create_demo_data(\n",
    "    batch_size=4, \n",
    "    seq_len=16, \n",
    "    d_model=config.d_model, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"üìä Demo Data Shape: {demo_data.shape}\")\n",
    "print(f\"üìä Data Range: [{demo_data.min():.3f}, {demo_data.max():.3f}]\")\n",
    "print(f\"üìä Data Mean: {demo_data.mean():.3f}\")\n",
    "print(f\"üìä Data Std: {demo_data.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(demo_data, compute_loss=True)\n",
    "    else:\n",
    "        output = model(demo_data, compute_loss=True)\n",
    "\n",
    "print(\"üîç Inference Results:\")\n",
    "print(f\"   Total Loss: {output['loss'].item():.6f}\")\n",
    "print(f\"   MSE Loss: {output['loss_components']['mse_loss'].item():.6f}\")\n",
    "print(f\"   L1 Loss: {output['loss_components']['l1_loss'].item():.6f}\")\n",
    "print(f\"   Temporal Loss: {output['loss_components']['temporal_loss'].item():.6f}\")\n",
    "\n",
    "print(f\"\\nüìè Output Shapes:\")\n",
    "print(f\"   Reconstructed: {output['output'].shape}\")\n",
    "print(f\"   Activations: {output['activations'].shape}\")\n",
    "\n",
    "# Compute reconstruction error\n",
    "recon_error = torch.mean((demo_data - output['output'])**2).item()\n",
    "print(f\"\\nüìä Reconstruction Error (MSE): {recon_error:.6f}\")\n",
    "\n",
    "# Compute sparsity metrics if available\n",
    "if hasattr(model, 'get_sparsity_metrics'):\n",
    "    sparsity_metrics = model.get_sparsity_metrics(output['activations'])\n",
    "    print(f\"\\nüéØ Sparsity Metrics:\")\n",
    "    for key, value in sparsity_metrics.items():\n",
    "        print(f\"   {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up Metric Hooks and Run Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metric hooks (with fallback)\n",
    "try:\n",
    "    from membench_x.metrics import (\n",
    "        MemAbsorptionHook, TPGHook, CapGaugeHook,\n",
    "        ICLPersistenceHook, WeightDeltaHook, RAGTraceHook\n",
    "    )\n",
    "    print(\"‚úÖ Imported metric hooks\")\nexcept ImportError:\n",
    "    print(\"‚ùå Could not import metric hooks, using fallback\")\n",
    "    # Fallback implementation would go here\n",
    "\n",
    "# Create temporary metrics directory\n",
    "metrics_dir = project_root / \"outputs\" / \"demo_metrics\"\n",
    "metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize metric hooks (without TensorBoard writer for simplicity)\n",
    "from unittest.mock import Mock\n",
    "mock_writer = Mock()\n",
    "\n",
    "metric_hooks = {\n",
    "    'mem_absorption': MemAbsorptionHook(mock_writer, metrics_dir),\n",
    "    'tpg': TPGHook(mock_writer, metrics_dir),\n",
    "    'cap_gauge': CapGaugeHook(mock_writer, metrics_dir),\n",
    "    'icl_persistence': ICLPersistenceHook(mock_writer, metrics_dir),\n",
    "    'weight_delta': WeightDeltaHook(mock_writer, metrics_dir),\n",
    "    'rag_trace': RAGTraceHook(mock_writer, metrics_dir)\n",
    "}\n",
    "\n",
    "print(f\"üéØ Created {len(metric_hooks)} metric hooks\")\n",
    "print(f\"üìÅ Metrics will be saved to: {metrics_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer for training steps\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Collect metrics over several training steps\n",
    "metrics_history = []\n",
    "num_steps = 10\n",
    "\n",
    "print(\"üöÄ Running training steps with metric collection...\")\n",
    "\n",
    "model.train()\n",
    "for step in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    if use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(demo_data, compute_loss=True)\n",
    "    else:\n",
    "        outputs = model(demo_data, compute_loss=True)\n",
    "    \n",
    "    loss = outputs['loss']\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Collect metrics\n",
    "    step_metrics = {'step': step, 'loss': loss.item()}\n",
    "    \n",
    "    for name, hook in metric_hooks.items():\n",
    "        try:\n",
    "            hook_metrics = hook.on_step(\n",
    "                step=step,\n",
    "                model=model,\n",
    "                activations=outputs['activations'],\n",
    "                loss_dict=outputs['loss_components']\n",
    "            )\n",
    "            step_metrics.update(hook_metrics)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Warning: {name} hook failed: {e}\")\n",
    "    \n",
    "    metrics_history.append(step_metrics)\n",
    "    \n",
    "    if step % 2 == 0:\n",
    "        print(f\"Step {step:2d}: Loss = {loss.item():.6f}\")\n",
    "\n",
    "print(f\"‚úÖ Completed {num_steps} training steps\")\n",
    "print(f\"üìä Collected metrics for {len(metrics_history)} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Metrics: The Six Dials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics for plotting\n",
    "steps = [m['step'] for m in metrics_history]\n",
    "losses = [m['loss'] for m in metrics_history]\n",
    "\n",
    "# Extract dial metrics (with fallbacks for missing values)\n",
    "def extract_metric(metric_name, default=0.0):\n",
    "    return [m.get(metric_name, default) for m in metrics_history]\n",
    "\n",
    "mem_absorption = extract_metric('mem_absorption')\n",
    "tpg = extract_metric('tpg')\n",
    "cap_gauge = extract_metric('cap_gauge')\n",
    "icl_persistence = extract_metric('icl_persistence')\n",
    "weight_delta = extract_metric('weight_delta')\n",
    "rag_trace = extract_metric('rag_trace')\n",
    "\n",
    "print(\"üìà Metrics extracted for visualization\")\n",
    "print(f\"   Steps: {len(steps)}\")\n",
    "print(f\"   Sample mem_absorption: {mem_absorption[:3]}\")\n",
    "print(f\"   Sample cap_gauge: {cap_gauge[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "fig.suptitle('ChronoSAE Training Metrics: The Six Dials Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(steps, losses, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "axes[0, 0].set_title('Training Loss', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Step')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_yscale('log')\n",
    "\n",
    "# Mem-Absorption Dial\n",
    "axes[0, 1].plot(steps, mem_absorption, 'r-', linewidth=2, marker='s', markersize=4)\n",
    "axes[0, 1].set_title('üß† Mem-Absorption', fontweight='bold', color='red')\n",
    "axes[0, 1].set_xlabel('Step')\n",
    "axes[0, 1].set_ylabel('Memory Ratio')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# TPG Dial\n",
    "axes[0, 2].plot(steps, tpg, 'g-', linewidth=2, marker='^', markersize=4)\n",
    "axes[0, 2].set_title('‚è∞ TPG (Temporal Policy Gradient)', fontweight='bold', color='green')\n",
    "axes[0, 2].set_xlabel('Step')\n",
    "axes[0, 2].set_ylabel('TPG Value')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Cap-Gauge Dial\n",
    "axes[1, 0].plot(steps, cap_gauge, 'orange', linewidth=2, marker='d', markersize=4)\n",
    "axes[1, 0].set_title('üìä Cap-Gauge (Capacity)', fontweight='bold', color='orange')\n",
    "axes[1, 0].set_xlabel('Step')\n",
    "axes[1, 0].set_ylabel('Capacity Utilization')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "# ICL-Persistence Dial\n",
    "axes[1, 1].plot(steps, icl_persistence, 'purple', linewidth=2, marker='v', markersize=4)\n",
    "axes[1, 1].set_title('üîÑ ICL-Persistence', fontweight='bold', color='purple')\n",
    "axes[1, 1].set_xlabel('Step')\n",
    "axes[1, 1].set_ylabel('Persistence Score')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "\n",
    "# Weight-Œî Dial\n",
    "axes[1, 2].plot(steps, weight_delta, 'brown', linewidth=2, marker='p', markersize=4)\n",
    "axes[1, 2].set_title('‚öñÔ∏è Weight-Œî (Change)', fontweight='bold', color='brown')\n",
    "axes[1, 2].set_xlabel('Step')\n",
    "axes[1, 2].set_ylabel('Weight Change')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# RAG-Trace Dial\n",
    "axes[2, 0].plot(steps, rag_trace, 'teal', linewidth=2, marker='h', markersize=4)\n",
    "axes[2, 0].set_title('üîç RAG-Trace (Retrieval)', fontweight='bold', color='teal')\n",
    "axes[2, 0].set_xlabel('Step')\n",
    "axes[2, 0].set_ylabel('RAG Score')\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "axes[2, 0].set_ylim(0, 1)\n",
    "\n",
    "# Summary statistics\n",
    "axes[2, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "üìã Training Summary:\n",
    "‚Ä¢ Steps: {len(steps)}\n",
    "‚Ä¢ Final Loss: {losses[-1]:.6f}\n",
    "‚Ä¢ Device: {device}\n",
    "‚Ä¢ Model Size: {model_size_mb:.1f} MB\n",
    "‚Ä¢ Parameters: {param_count:,}\n",
    "\n",
    "üéØ Final Dial Readings:\n",
    "‚Ä¢ Mem-Absorption: {mem_absorption[-1]:.3f}\n",
    "‚Ä¢ Cap-Gauge: {cap_gauge[-1]:.3f}\n",
    "‚Ä¢ ICL-Persistence: {icl_persistence[-1]:.3f}\n",
    "‚Ä¢ Weight-Œî: {weight_delta[-1]:.6f}\n",
    "‚Ä¢ TPG: {tpg[-1]:.6f}\n",
    "‚Ä¢ RAG-Trace: {rag_trace[-1]:.3f}\n",
    "\"\"\"\n",
    "axes[2, 1].text(0.05, 0.95, summary_text, transform=axes[2, 1].transAxes, \n",
    "                fontsize=10, verticalalignment='top', \n",
    "                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "# Device info\n",
    "axes[2, 2].axis('off')\n",
    "device_info = f\"\"\"\n",
    "üíª System Info:\n",
    "‚Ä¢ Device: {device}\n",
    "‚Ä¢ Mixed Precision: {use_amp}\n",
    "‚Ä¢ PyTorch: {torch.__version__}\n",
    "\n",
    "üìÅ Output Locations:\n",
    "‚Ä¢ Metrics: {metrics_dir.name}/\n",
    "‚Ä¢ Plots: notebooks/\n",
    "\n",
    "üîó Quick Links:\n",
    "‚Ä¢ JSONL files in metrics/\n",
    "‚Ä¢ Checkpoints in outputs/\n",
    "‚Ä¢ Config: configs/pythia70m.yml\n",
    "\"\"\"\n",
    "axes[2, 2].text(0.05, 0.95, device_info, transform=axes[2, 2].transAxes,\n",
    "                fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = project_root / \"notebooks\" / \"chrono_sae_dashboard.png\"\n",
    "fig.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"üíæ Dashboard saved to: {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Examine Saved Metrics (JSONL Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all JSONL files in metrics directory\n",
    "jsonl_files = list(metrics_dir.glob(\"*.jsonl\"))\n",
    "print(f\"üìÅ Found {len(jsonl_files)} JSONL metric files:\")\n",
    "\n",
    "for file_path in jsonl_files:\n",
    "    print(f\"   ‚Ä¢ {file_path.name}\")\n",
    "\n",
    "# Display contents of a few metric files\n",
    "for file_path in jsonl_files[:3]:  # Show first 3 files\n",
    "    print(f\"\\nüìä Contents of {file_path.name}:\")\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"   Lines: {len(lines)}\")\n",
    "            \n",
    "            # Show first few entries\n",
    "            for i, line in enumerate(lines[:3]):\n",
    "                data = json.loads(line.strip())\n",
    "                print(f\"   Entry {i}: step={data['step']}, value={data['value']:.6f}\")\n",
    "                \n",
    "            if len(lines) > 3:\n",
    "                print(f\"   ... and {len(lines) - 3} more entries\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error reading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze one specific metric file\n",
    "if jsonl_files:\n",
    "    # Focus on mem_absorption as an example\n",
    "    mem_file = None\n",
    "    for f in jsonl_files:\n",
    "        if 'mem_absorption' in f.name:\n",
    "            mem_file = f\n",
    "            break\n",
    "    \n",
    "    if mem_file:\n",
    "        print(f\"üîç Detailed analysis of {mem_file.name}:\")\n",
    "        \n",
    "        # Load all data\n",
    "        mem_data = []\n",
    "        with open(mem_file, 'r') as f:\n",
    "            for line in f:\n",
    "                mem_data.append(json.loads(line.strip()))\n",
    "        \n",
    "        # Analyze the data\n",
    "        values = [d['value'] for d in mem_data]\n",
    "        steps = [d['step'] for d in mem_data]\n",
    "        \n",
    "        print(f\"   üìä Statistics:\")\n",
    "        print(f\"      ‚Ä¢ Total entries: {len(values)}\")\n",
    "        print(f\"      ‚Ä¢ Min value: {min(values):.6f}\")\n",
    "        print(f\"      ‚Ä¢ Max value: {max(values):.6f}\")\n",
    "        print(f\"      ‚Ä¢ Mean value: {np.mean(values):.6f}\")\n",
    "        print(f\"      ‚Ä¢ Std deviation: {np.std(values):.6f}\")\n",
    "        print(f\"      ‚Ä¢ Step range: {min(steps)} - {max(steps)}\")\n",
    "        \n",
    "        # Show trend\n",
    "        if len(values) >= 2:\n",
    "            trend = \"‚ÜóÔ∏è increasing\" if values[-1] > values[0] else \"‚ÜòÔ∏è decreasing\"\n",
    "            change = abs(values[-1] - values[0])\n",
    "            print(f\"      ‚Ä¢ Trend: {trend} (change: {change:.6f})\")\n",
    "    else:\n",
    "        print(\"üîç No mem_absorption file found for detailed analysis\")\nelse:\n",
    "    print(\"üìÅ No JSONL files found - metrics may not have been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Assessment & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance summary\n",
    "print(\"üèÅ CHRONO-SAE QUICKSTART COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully demonstrated:\")\n",
    "print(f\"   ‚Ä¢ Environment setup and device detection\")\n",
    "print(f\"   ‚Ä¢ ChronoSAE model creation and configuration\")\n",
    "print(f\"   ‚Ä¢ Forward pass inference with loss computation\")\n",
    "print(f\"   ‚Ä¢ Training loop with {num_steps} optimization steps\")\n",
    "print(f\"   ‚Ä¢ Six-dial metric collection and streaming\")\n",
    "print(f\"   ‚Ä¢ Real-time visualization dashboard\")\n",
    "print(f\"   ‚Ä¢ JSONL metric persistence and analysis\")\n",
    "\n",
    "print(f\"\\nüìä Model Performance:\")\n",
    "print(f\"   ‚Ä¢ Initial Loss: {losses[0]:.6f}\")\n",
    "print(f\"   ‚Ä¢ Final Loss: {losses[-1]:.6f}\")\n",
    "print(f\"   ‚Ä¢ Loss Reduction: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%\")\n",
    "print(f\"   ‚Ä¢ Training Stability: {'‚úÖ Stable' if losses[-1] < losses[0] else '‚ö†Ô∏è Unstable'}\")\n",
    "\n",
    "print(f\"\\nüéØ Dial Summary:\")\n",
    "dial_summary = {\n",
    "    'Mem-Absorption': mem_absorption[-1],\n",
    "    'TPG': tpg[-1], \n",
    "    'Cap-Gauge': cap_gauge[-1],\n",
    "    'ICL-Persistence': icl_persistence[-1],\n",
    "    'Weight-Œî': weight_delta[-1],\n",
    "    'RAG-Trace': rag_trace[-1]\n",
    "}\n",
    "\n",
    "for dial, value in dial_summary.items():\n",
    "    status = \"üü¢\" if 0.1 <= value <= 0.9 else \"üü°\" if value > 0 else \"üî¥\"\n",
    "    print(f\"   ‚Ä¢ {dial}: {value:.4f} {status}\")\n",
    "\n",
    "print(f\"\\nüîó Next Steps:\")\n",
    "print(f\"   1. Experiment with different model configurations\")\n",
    "print(f\"   2. Try training on real transformer activations\")\n",
    "print(f\"   3. Explore checkpoint saving/loading: training/train.py\")\n",
    "print(f\"   4. Scale up with multi-GPU training using torchrun\")\n",
    "print(f\"   5. Analyze saved metrics: {metrics_dir}/*.jsonl\")\n",
    "print(f\"   6. Visualize longer training runs with TensorBoard\")\n",
    "\n",
    "print(f\"\\nüìÅ Generated Files:\")\n",
    "print(f\"   ‚Ä¢ Dashboard: notebooks/chrono_sae_dashboard.png\")\n",
    "print(f\"   ‚Ä¢ Metrics: {metrics_dir.relative_to(project_root)}/*.jsonl\")\n",
    "print(f\"   ‚Ä¢ Config: configs/pythia70m.yml\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready for production training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (optional)\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory if using CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üßπ GPU memory cleared\")\n",
    "\n",
    "# Python garbage collection\n",
    "gc.collect()\n",
    "print(\"üßπ Python garbage collection completed\")\n",
    "\n",
    "print(\"\\n‚ú® Notebook execution complete! ‚ú®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
